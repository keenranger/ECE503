{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.3 64-bit ('base': conda)",
      "metadata": {
        "interpreter": {
          "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
        }
      }
    },
    "colab": {
      "name": "project2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDm7WVm4eyFl"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FJeR3_meyFl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "device = torch.device(\"cuda\")\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9OQ2FLgeyFl"
      },
      "source": [
        "# Develop a code in Matlab (or Python) to design a neural network to perform 10 digit classification.  \n",
        "## Make 3 different networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCo1kdO9eyFl"
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3= nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        h1 = F.relu(self.fc1(x.view(-1, 784)))\n",
        "        h2 = F.relu(self.fc2(h1))\n",
        "        h3 = self.fc3(h2)\n",
        "        return F.log_softmax(h3, dim=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7ER1ypaeyFl"
      },
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        h1 = F.relu(self.fc1(x.view(-1, 784)))\n",
        "        h2 = F.relu(self.fc2(h1))\n",
        "        h3 = F.relu(self.fc3(h2))\n",
        "        h4 = self.fc4(h3)\n",
        "        return F.log_softmax(h4, dim=1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2T3k0NceyFl"
      },
      "source": [
        "class Net3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net3, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        h1 = F.relu(self.fc1(x.view(-1, 784)))\n",
        "        h2 = F.relu(self.fc2(h1))\n",
        "        h3 = F.relu(self.fc3(h2))\n",
        "        h4 = F.relu(self.fc4(h3))\n",
        "        h5 = F.relu(self.fc5(h4))\n",
        "        h6 = self.fc6(h5)\n",
        "        return F.log_softmax(h6, dim=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHLQ573heyFl"
      },
      "source": [
        "# Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q16r7dNPeyFl"
      },
      "source": [
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "epochs = 10\n",
        "lr = 0.01\n",
        "momentum = 0.5\n",
        "no_cuda= True\n",
        "seed = 1\n",
        "log_interval = 200"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d96RP8geeyFl"
      },
      "source": [
        "# Load MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze8LuWw5eyFl"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                 transforms.ToTensor(),\n",
        "                 transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  datasets.MNIST('../data', train=True, download=True, \n",
        "                 transform=transform), \n",
        "    batch_size = batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, download=True,\n",
        "                 transform=transform), \n",
        "    batch_size=test_batch_size, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdNPRLX2eyFl"
      },
      "source": [
        "# Make model for each network made before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpuo4H6AeyFl"
      },
      "source": [
        "\n",
        "model1 = Net1().to(device)\n",
        "model2 = Net2().to(device)\n",
        "model3 = Net3().to(device)\n",
        "\n",
        "optimizer1 = optim.SGD(model1.parameters(), lr=lr, momentum=momentum)\n",
        "optimizer2 = optim.SGD(model2.parameters(), lr=lr, momentum=momentum)\n",
        "optimizer3 = optim.SGD(model3.parameters(), lr=lr, momentum=momentum)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTpPdlLAeyFl"
      },
      "source": [
        "# Make function for train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-bm1YqoeyFl"
      },
      "source": [
        "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(log_interval, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() \n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format\n",
        "          (test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s763IRTzgH5E"
      },
      "source": [
        "# Compare three different model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFn1atQpeyFl",
        "outputId": "6182699d-1e81-4746-f17d-c1db85d29d66"
      },
      "source": [
        "for epoch in range(1, 11):\n",
        "    train(log_interval, model1, device, train_loader, optimizer1, epoch)\n",
        "    test(log_interval, model1, device, test_loader)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.323502\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.550751\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.506593\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.271568\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.139545\n",
            "\n",
            "Test set: Average loss: 0.2600, Accuracy: 9247/10000 (92%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.301322\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.322190\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.167458\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.121579\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.310232\n",
            "\n",
            "Test set: Average loss: 0.1907, Accuracy: 9435/10000 (94%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.169913\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.202752\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.097531\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.131907\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.087788\n",
            "\n",
            "Test set: Average loss: 0.1545, Accuracy: 9546/10000 (95%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.108013\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.159659\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.074042\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.086218\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.185188\n",
            "\n",
            "Test set: Average loss: 0.1363, Accuracy: 9590/10000 (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.077776\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.107382\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.117365\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.076149\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.059572\n",
            "\n",
            "Test set: Average loss: 0.1096, Accuracy: 9660/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.094241\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.081501\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.045341\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.153225\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.130824\n",
            "\n",
            "Test set: Average loss: 0.1001, Accuracy: 9698/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.059190\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.074502\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.059176\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.159472\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.075928\n",
            "\n",
            "Test set: Average loss: 0.0915, Accuracy: 9716/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.028207\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.172081\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.043184\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.042910\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.027707\n",
            "\n",
            "Test set: Average loss: 0.0883, Accuracy: 9733/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.076917\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.112053\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.029144\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.081128\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.027481\n",
            "\n",
            "Test set: Average loss: 0.0794, Accuracy: 9755/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.035704\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.033602\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.027371\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.044065\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.065613\n",
            "\n",
            "Test set: Average loss: 0.0758, Accuracy: 9766/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5hodlsmeyFm",
        "outputId": "0cbb9957-cad2-4a0f-f7ee-558309a1d2f1"
      },
      "source": [
        "for epoch in range(1, 11):\n",
        "    train(log_interval, model2, device, train_loader, optimizer2, epoch)\n",
        "    test(log_interval, model2, device, test_loader)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.317862\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.268878\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.399253\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.431553\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.324344\n",
            "\n",
            "Test set: Average loss: 0.2809, Accuracy: 9168/10000 (92%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.367965\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.083491\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.213421\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.244003\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.124480\n",
            "\n",
            "Test set: Average loss: 0.1846, Accuracy: 9445/10000 (94%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.142018\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.163642\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.097687\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.132001\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.245406\n",
            "\n",
            "Test set: Average loss: 0.1376, Accuracy: 9576/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.107058\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.096857\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.046428\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.184138\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.108537\n",
            "\n",
            "Test set: Average loss: 0.1204, Accuracy: 9630/10000 (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.035956\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.149257\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.214899\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.047788\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.110369\n",
            "\n",
            "Test set: Average loss: 0.0972, Accuracy: 9706/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.020458\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.062912\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.084084\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.096087\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.046205\n",
            "\n",
            "Test set: Average loss: 0.0921, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.100553\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.028458\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.061970\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.107361\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.037580\n",
            "\n",
            "Test set: Average loss: 0.0831, Accuracy: 9739/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.110368\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.035876\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.028674\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.042144\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.020614\n",
            "\n",
            "Test set: Average loss: 0.0853, Accuracy: 9740/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.048795\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.055714\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.090455\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.219562\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.018364\n",
            "\n",
            "Test set: Average loss: 0.0822, Accuracy: 9758/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.039883\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.013997\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.012402\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.026251\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.009806\n",
            "\n",
            "Test set: Average loss: 0.0764, Accuracy: 9755/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sLrEXCVeyFm",
        "outputId": "724e4de1-c2cc-4008-ab2b-f806ffd1c82a"
      },
      "source": [
        "for epoch in range(1, 11):\n",
        "    train(log_interval, model3, device, train_loader, optimizer3, epoch)\n",
        "    test(log_interval, model3, device, test_loader)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.288403\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.299635\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.278328\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.969087\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.828705\n",
            "\n",
            "Test set: Average loss: 0.5952, Accuracy: 8164/10000 (82%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.544774\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.331564\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.315510\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.206456\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.172777\n",
            "\n",
            "Test set: Average loss: 0.2294, Accuracy: 9307/10000 (93%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.116710\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.209312\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.211858\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.113646\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.106659\n",
            "\n",
            "Test set: Average loss: 0.1634, Accuracy: 9486/10000 (95%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.079951\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.056103\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.093495\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.097952\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.069506\n",
            "\n",
            "Test set: Average loss: 0.1195, Accuracy: 9657/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.069163\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.175185\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.093016\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.029534\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.111629\n",
            "\n",
            "Test set: Average loss: 0.1394, Accuracy: 9565/10000 (96%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.024933\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.081692\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.056436\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.053458\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.031962\n",
            "\n",
            "Test set: Average loss: 0.1024, Accuracy: 9705/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.132719\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.065110\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.060301\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.085895\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.021193\n",
            "\n",
            "Test set: Average loss: 0.0880, Accuracy: 9733/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.024128\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.005721\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.024721\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.007953\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.009433\n",
            "\n",
            "Test set: Average loss: 0.1113, Accuracy: 9671/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.124851\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.033748\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.004373\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.034579\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.027317\n",
            "\n",
            "Test set: Average loss: 0.0820, Accuracy: 9759/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.005777\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.014398\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.010600\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.054136\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.056273\n",
            "\n",
            "Test set: Average loss: 0.0874, Accuracy: 9743/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g3dG4G_g8S5"
      },
      "source": [
        "# Discussion  \n",
        "As I use quite big networks for MNIST dataset, you can see results among models are quite similar. But you might notice that smaller network converges faster than the others, since it has less parameters to be trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl3rIELVeyFm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}